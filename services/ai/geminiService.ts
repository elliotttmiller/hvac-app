// backend/ai/geminiService.ts

import { GoogleGenAI, Part, Content } from "@google/genai";
import { ProjectMetadata, ManualJInput } from '../../types';
import { SYSTEM_PROMPTS, KNOWLEDGE_BASE } from './prompts';

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
const VISION_MODEL_NAME = 'gemini-2.5-pro';
const LOGIC_MODEL_NAME = 'gemini-2.5-flash';

export interface VisionTakeoffResult {
  projectMetadata: ProjectMetadata;
  roomList: Array<{ name: string; area: number; }>;
  totalEnvelope: {
    conditionedFloorArea: number;
    exteriorWallArea: number;
    windowArea: number;
    doorArea: number;
    roofArea: number;
  };
  inferredScale: string;
  // Added to satisfy PipelineOrchestrator expectations
  designParameters: {
    infiltrationMethod: string;
    constructionQuality: string;
  };
}

// Renamed from extractProjectDataFromPDF to match PipelineOrchestrator import
export async function extractTakeoffFromPDF(imageParts: Part[]): Promise<VisionTakeoffResult> {
  try {
    const response = await ai.models.generateContent({
      model: VISION_MODEL_NAME,
      contents: [
        {
          role: 'user',
          parts: [...imageParts, { text: SYSTEM_PROMPTS.VISION_EXTRACTION }]
        }
      ],
      config: {
        responseMimeType: 'application/json'
      }
    });

    if (!response.text) {
      throw new Error("No response text generated by Vision Model");
    }

    const result = JSON.parse(response.text) as VisionTakeoffResult;

    // Ensure designParameters exists for the Orchestrator
    return {
      ...result,
      designParameters: result.designParameters || {
        infiltrationMethod: 'Simplified',
        constructionQuality: 'Average'
      }
    };

  } catch (error: any) {
    console.error("Error in Vision Takeoff Pipeline:", error);
    // Return safe fallback to prevent app crash
    return {
        projectMetadata: { jobName: "Extraction Error", clientName: "", clientCompany: "", designerName: "", planName: "", reportDate: "" },
        roomList: [],
        totalEnvelope: { conditionedFloorArea: 0, exteriorWallArea: 0, windowArea: 0, doorArea: 0, roofArea: 0 },
        inferredScale: "N/A",
        designParameters: { infiltrationMethod: 'Simplified', constructionQuality: 'Average' }
    };
  }
}

export async function normalizeDataForPhysics(visionResult: VisionTakeoffResult): Promise<ManualJInput> {
  try {
    const promptText = SYSTEM_PROMPTS.LOGIC_NORMALIZATION(
        JSON.stringify(KNOWLEDGE_BASE),
        JSON.stringify(visionResult)
    );

    const response = await ai.models.generateContent({
      model: LOGIC_MODEL_NAME,
      contents: [
        {
          role: 'user',
          parts: [{ text: promptText }]
        }
      ],
      config: {
        responseMimeType: 'application/json'
      }
    });
    
    if (!response.text) {
      throw new Error("No response text generated by Logic Model");
    }

    return JSON.parse(response.text) as ManualJInput;

  } catch (error: any) {
    console.error("Error in Logic Normalization:", error);
    throw new Error(`AI failed to prepare physics input: ${error.message}`);
  }
}

export async function fetchEquipmentScenarios(coolingLoad: number, heatingLoad: number): Promise<any> {
  // Placeholder implementation to satisfy interface
  return {
    recommended: [],
    notes: "Equipment grounding requires Google Search tool implementation."
  };
}